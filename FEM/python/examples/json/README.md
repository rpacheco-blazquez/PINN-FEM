# Examples - JSON Input Format

Este directorio contiene ejemplos de problemas FEM resueltos con diferentes m√©todos num√©ricos.

## üìÅ Archivos Principales

### `example1.json` - Newton-Raphson (FEM Cl√°sico)
**Descripci√≥n:** Problema FEM forward con solver Newton-Raphson.

**Configuraci√≥n:**
- **Geometr√≠a:** 3 barras horizontales en serie (4 nodos en x=0,1,2,3)
- **Material:** E=1.0, A=1.0, œÅ=1.0
- **Condiciones de contorno:** Nodo 0 fijo, nodos 1-3 solo libres en direcci√≥n x
- **Carga:** F=1.0 N aplicada en nodo 3 (direcci√≥n x)
- **Solver:** `"solver_type": "fem"` (Newton-Raphson)
- **Par√°metros:** max_iterations=50, tolerance=1e-6

**Soluci√≥n te√≥rica:**
```
u = [0, 1, 2, 3] metros
```

**Resultados:**
- Iteraciones: **10**
- Convergencia: ‚úì S√≠
- Precisi√≥n: ~1e-16 (precisi√≥n de m√°quina)

---

### `example2.json` - Gradient Descent (PINN-GD)
**Descripci√≥n:** Mismo problema que Example 1 pero resuelto con Gradient Descent.

**Configuraci√≥n:**
- **Geometr√≠a:** Id√©ntica a Example 1
- **Material:** Id√©ntico a Example 1
- **Solver:** `"solver_type": "pinn-gd"` (Gradient Descent con Adam)
- **Par√°metros:**
  ```json
  "solver_config": {
    "max_iterations": 10000,
    "tolerance": 1e-6,
    "learning_rate_u": 0.01,
    "alpha_residual": 1.0,
    "print_every": 1000
  }
  ```

**Resultados:**
- Iteraciones: **~3035**
- Convergencia: ‚úì S√≠ (residual < 1e-6)
- Precisi√≥n: ~1e-6 (error < 4 micrones)

---

### `example3.json` - PINN Inverse Problem (NN Material Properties)
**Descripci√≥n:** Problema inverso donde una red neuronal aprende E(x,y) a partir de mediciones de desplazamientos.

**Configuraci√≥n:**
- **Geometr√≠a:** Id√©ntica a Examples 1 & 2
- **Material:** Young's modulus representado por NN(x,y) con 2 capas ocultas de 20 neuronas
- **Measurements:** Desplazamientos medidos en nodos 1, 2, 3: [1.0, 2.0, 3.0] m
- **Solver:** `"solver_type": "pinn-gd"` (Gradient Descent con Adam)
- **Loss function:** 
  ```
  L = Œ±_physics * ||R||¬≤ + Œ±_data * ||u_measured - u||¬≤
  ```
- **Par√°metros:**
  ```json
  "pinn_config": {
    "learning_rate_u": 0.01,
    "learning_rate_theta": 0.001,
    "alpha_physics": 1.0,
    "alpha_data": 100.0,
    "max_iterations": 5000,
    "tolerance": 1e-6
  }
  ```

**Arquitectura de NN:**
```python
Input: (x, y) ‚Üí Hidden(20) ‚Üí Tanh ‚Üí Hidden(20) ‚Üí Tanh ‚Üí Output(1)
Young = softplus(NN(x,y)) * scale  # Garantiza E > 0
```

**Resultados:**
- Iteraciones: **1110**
- Convergencia: ‚úì S√≠ (loss=9.85e-07)
- Final loss_physics: 6.798e-07 (excellent equilibrium)
- Final loss_data: 1.976e-07 (fits measurements perfectly)
- NN parameters: 501 trainable params (20√ó2 + 20 + 20√ó20 + 20 + 1√ó20 + 1)

**Desplazamientos finales vs medidos:**
| Nodo | Measured | Predicted | Error (%) |
|------|----------|-----------|-----------|
| 1    | 1.0000   | 0.9998    | 0.02%     |
| 2    | 2.0000   | 2.0000    | 0.002%    |
| 3    | 3.0000   | 2.9998    | 0.008%    |

**Conclusi√≥n:** El PINN aprende correctamente E(x,y) que satisface tanto las ecuaciones de f√≠sica como los datos medidos.

---

### `example4.json` - PINN con TODAS las Propiedades como NN  
**Descripci√≥n:** Problema inverso avanzado donde m√∫ltiples redes neuronales aprenden E(x,y), A(x,y) y œÅ(x,y) simult√°neamente.

**Configuraci√≥n:**
- **Geometr√≠a:** Id√©ntica a Examples 1, 2 & 3
- **Material:** Todas las propiedades representadas por NNs independientes
- **Measurements:** Mismos desplazamientos medidos: [1.0, 2.0, 3.0] m
- **Solver:** `"solver_type": "pinn-gd"` (Gradient Descent con Adam)
- **Arquitecturas de NN:**
  - Young: NN(x,y) ‚Üí 2√ó20√ó20√ó1 = 501 params
  - Area: NN(x,y) ‚Üí 2√ó15√ó15√ó1 = 316 params  
  - Density: NN(x,y) ‚Üí 2√ó10√ó10√ó1 = 141 params
  - **Total: 958 par√°metros entrenables**

**Par√°metros:**
```json
"nn_config": {
  "young": {"enabled": true, "input_dim": 2, "neurons_per_layer": 20},
  "area": {"enabled": true, "input_dim": 2, "neurons_per_layer": 15},
  "density": {"enabled": true, "input_dim": 2, "neurons_per_layer": 10}
},
"pinn_config": {
  "learning_rate_theta": 0.0005  // M√°s lento para estabilidad
}
```

**Resultados:**
- Iteraciones: **2684** (m√°s que example3 debido a m√°s par√°metros)
- Convergencia: ‚úì S√≠ (loss=9.97e-07)
- NN parameters: ~24.26 (vs 8.9 en example3)

**Predicciones de las 3 NNs (centroides de elementos):**
| Elemento | Young (E) | Area (A) | Density (œÅ) | **E√óA** |
|----------|-----------|----------|-------------|---------|
| 0        | 0.998     | 1.002    | 1.269       | **1.000** |
| 1        | 0.966     | 1.034    | 1.291       | **0.999** |
| 2        | 0.939     | 1.065    | 1.306       | **1.000** |

**An√°lisis de Coherencia:**
- ‚úÖ **Compensaci√≥n inteligente:** E‚Üì mientras A‚Üë para mantener rigidez EA‚âà1.0
- ‚úÖ **Convergencia cooperativa:** 3 NNs trabajando juntas en lugar de competir
- ‚úÖ **F√≠sica respetada:** œÅ no afecta la est√°tica, solo participa marginalmente

**Conclusi√≥n:** Las m√∫ltiples NNs aprenden relaciones f√≠sicas complejas distribuyendo roles cooperativamente para satisfacer equilibrio + datos.

---

## üìä Comparaci√≥n de Resultados

### Tabla de Ejemplos
| Example | Solver | Material | Iterations | NN Params | Purpose |
|---------|--------|----------|------------|-----------|---------|
| example1.json | Newton-Raphson | E=1.0 (constante) | 10 | 0 | Forward problem (cl√°sico FEM) |
| example2.json | Gradient Descent | E=1.0 (constante) | 3035 | 0 | Forward problem (PINN-GD) |
| example3.json | Gradient Descent | E=NN(x,y) | 1110 | 501 | Inverse problem (learn E from data) |
| example4.json | Gradient Descent | E,A,œÅ=NN(x,y) | 2684 | 958 | Multi-property inverse problem |

### Desplazamientos Nodales(Examples 1 & 2)
| Nodo | Example1 (NR) | Example2 (GD) | Diferencia |
|------|---------------|---------------|------------|
| 0    | 0.000000      | 0.000000      | 0.00e+00   |
| 1    | 1.000000      | 0.999998      | 1.79e-06   |
| 2    | 2.000000      | 1.999997      | 2.98e-06   |
| 3    | 3.000000      | 2.999996      | 3.58e-06   |

### Eficiencia Computacional
| M√©todo            | Iteraciones | Ratio vs NR | NN Params |
|-------------------|-------------|-------------|-----------|
| Newton-Raphson (E=const) | 10     | 1x          | 0         |
| Gradient Descent (E=const) | 3035 | **303x**    | 0         |
| Gradient Descent (E=NN, inverse) | 1110 | **111x** | 501       |
| Gradient Descent (E,A,œÅ=NN, multi) | 2684 | **268x** | 958       |

**Conclusi√≥n:** Para problemas FEM lineales forward, Newton-Raphson es ~300x m√°s eficiente. Para problemas inversos con NN, GD es la √∫nica opci√≥n (NR no puede optimizar propiedades). La complejidad crece sub-linealmente con el n√∫mero de NNs.

---

## üöÄ C√≥mo Ejecutar

### Ejecutar Example 1 (Newton-Raphson)
```bash
cd FEM/python
python examples/json/generic.py examples/json/example1.json
```

### Ejecutar Example 2 (Gradient Descent)
```bash
cd FEM/python
python examples/json/generic.py examples/json/example2.json
```

### Ejecutar Example 3 (PINN Inverse Problem)
```bash
cd FEM/python
python examples/json/generic.py examples/json/example3.json
```

### Ejecutar Example 4 (PINN Multi-Property)  
```bash
cd FEM/python
python examples/json/generic.py examples/json/example4.json
```

### Archivos de Salida
Cada ejecuci√≥n genera:
- `exampleX.res.json` - Resultados (desplazamientos, reacciones, convergencia, historial de loss)
- `exampleX.log` - Log detallado de la ejecuci√≥n

---

## üìù Notas Importantes

### Cu√°ndo usar Newton-Raphson (Example 1)
‚úì Problemas FEM forward lineales  
‚úì Materiales con propiedades conocidas  
‚úì M√°xima eficiencia computacional  
‚úì Convergencia cuadr√°tica (muy r√°pida)  

### Cu√°ndo usar Gradient Descent sin NN (Example 2)
‚úì Validaci√≥n de implementaci√≥n PINN-GD  
‚úì Comparaci√≥n con Newton-Raphson  
‚úì Debugging de solver GD  

### Cu√°ndo usar PINN con NN (Examples 3 & 4)
‚úì **Problemas inversos:** identificar propiedades materiales desde mediciones  
‚úì **Material heterog√©neo:** E(x,y,z) var√≠a espacialmente  
‚úì **Data-driven modeling:** aprender constitutive laws desde experimentos  
‚úì **Physics-informed learning:** combinar ecuaciones f√≠sicas + datos  
‚úì **Multi-property identification:** identificar m√∫ltiples propiedades simult√°neamente (Example 4)  

### Par√°metros Cr√≠ticos para GD
‚ö†Ô∏è **IMPORTANTE:** El learning rate debe configurarse correctamente:
```json
"pinn_config": {
  "learning_rate_u": 0.01,      // Learning rate para desplazamientos
  "learning_rate_theta": 0.001  // Learning rate para par√°metros de NN
}
```

Con `lr_u=1e-7` (default), GD tarda ~1,000,000 iteraciones. Con `lr_u=0.01`, converge en ~3000.

### Estructura de Loss para PINN (Example 3)
```python
# Loss total
L = Œ±_physics * L_physics + Œ±_data * L_data

# Physics loss (equilibrio)
L_physics = 0.5 * ||R||¬≤ = 0.5 * ||f_internal - f_external||¬≤

# Data loss (ajuste a mediciones)
L_data = ||u_measured - u_predicted||¬≤

# Pesos recomendados
Œ±_physics = 1.0    # Siempre > 0 (garantiza equilibrio)
Œ±_data = 100.0     # Mayor peso ‚Üí mejor ajuste a datos
```

---

## üîç Archivos Adicionales

### `example1-1.json` / `example2-2.json`
Casos de prueba con **1 solo elemento** para debugging y validaci√≥n:
- `example1-1.json`: 1 elemento, Newton-Raphson
- `example2-2.json`: 1 elemento, Gradient Descent (~352 iteraciones)

### `generic.py`
Parser y ejecutor principal que:
1. Lee el archivo JSON de entrada
2. Construye el modelo FEM
3. Invoca el solver apropiado
4. Escribe resultados en formato JSON

---

## üìñ Formato JSON de Entrada

### Formato B√°sico (Examples 1 & 2)
```json
{
  "description": "Descripci√≥n del problema",
  "nodes": [
    {"x": 0.0, "y": 0.0, "fixed_x": true, "fixed_y": true}
  ],
  "elements": [[0, 1], [1, 2]],
  "loads": [0.0, 0.0, 1.0, 0.0],
  "material": {
    "young": 1.0,
    "area": 1.0,
    "density": 1.0
  },
  "solver_type": "fem" | "pinn-gd",
  "solver_config": {
    "max_iterations": 50,
    "tolerance": 1e-6,
    "learning_rate_u": 0.01  // Solo para pinn-gd
  }
}
```

### Formato Avanzado con PINN (Examples 3 & 4)
```json
{
  "description": "PINN inverse problem",
  "nodes": [...],
  "elements": [[0, 1], [1, 2]],
  "loads": [...],
  "material": {
    "young": 1.0,    // Usado como scale factor para NN
    "area": 1.0,     // Si NN enabled, usado como scale
    "density": 1.0   // Si NN enabled, usado como scale
  },
  "nn_config": {
    "young": {
      "enabled": true,
      "input_dim": 2,            // 1=(x), 2=(x,y), 3=(x,y,z)
      "hidden_layers": 2,
      "neurons_per_layer": 20
    },
    "area": {                    // Example 4: Multiple NNs
      "enabled": true,
      "input_dim": 2,
      "hidden_layers": 2,
      "neurons_per_layer": 15
    },
    "density": {                 // Example 4: Multiple NNs
      "enabled": true,
      "input_dim": 2,
      "hidden_layers": 2,
      "neurons_per_layer": 10
    }
  },
  "measured_displacements": {
    "nodes": [1, 2, 3],          // Node IDs con mediciones
    "ux": [1.0, 2.0, 3.0],       // Despl. en x
    "uy": [0.0, 0.0, 0.0]        // Despl. en y
  },
  "solver_type": "pinn-gd",
  "pinn_config": {
    "learning_rate_u": 0.01,
    "learning_rate_theta": 0.001,
    "alpha_physics": 1.0,
    "alpha_data": 100.0,
    "max_iterations": 5000,
    "tolerance": 1e-6,
    "print_every": 100
  }
}
```

**Campos clave para PINN:**
- `nn_config`: Define qu√© propiedades usan NN y su arquitectura
- `measured_displacements`: Datos experimentales para problem inverse
- `pinn_config`: Hiperpar√°metros de training (learning rates, alpha weights)

Para m√°s detalles ver `generic.py`.
